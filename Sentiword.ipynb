{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import pos_tag\n",
    "import json\n",
    "import sys\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Deprecated. See get_score()\n",
    "def get_scores(word, postag):\n",
    "    \"\"\"  Function to get sentiment scores from SentiWordNet.\n",
    "    Args:\n",
    "        word: word to get sentiment scores\n",
    "        postag: pos tag of the word\n",
    "    Returns:\n",
    "        score: a senti_synset instance that has negative, positive and neutral\n",
    "        scores of the word\"\"\"\n",
    "\n",
    "    if postag == \"Noun\":  # NOUN\n",
    "        score = swn.senti_synset(word + '.n.01')\n",
    "        return score\n",
    "    elif postag == \"Verb\":  # VERB\n",
    "        score = swn.senti_synset(word + '.v.01')\n",
    "        return score\n",
    "    elif postag == \"Adjective\":  # ADJECTIVE\n",
    "        score = swn.senti_synset(word + '.a.01')\n",
    "        return score\n",
    "    elif postag == \"Adverb\":  # ADVERB\n",
    "        score = swn.senti_synset(word + '.r.01')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "with open('./prep-neg.json') as data_file:\n",
    "    data = data_file.readlines()\n",
    "\n",
    "data = [x.strip() for x in data]\n",
    "jsonSentences = [json.loads(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk\n",
      "age\n",
      "formula\n",
      "cat\n",
      "attractive\n",
      "come\n",
      "veterinary\n",
      "side\n",
      "strongly\n",
      "to\n",
      "be\n",
      "taken\n",
      "direction\n",
      "warn\n",
      "brand\n",
      "minnoş\n",
      "blackout\n",
      "veterinary\n",
      "give\n",
      "scolding\n",
      "hear\n",
      "in\n",
      "the\n",
      "future\n",
      "bowel\n",
      "pee\n",
      "way\n",
      "28\n",
      "problem\n",
      "way\n",
      "flow\n",
      "say\n",
      "order\n",
      "make\n",
      "veterinary\n",
      "consult\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "# Row 6217, there is only posTag!!!\n",
    "for i in range(len(jsonSentences[6216])):\n",
    "    try:\n",
    "        print(jsonSentences[6216][i][\"word\"])\n",
    "    except Exception as e:\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/14881 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 44/14881 [00:00<00:34, 434.32it/s]\u001b[A\n",
      "  1%|          | 87/14881 [00:00<00:34, 427.83it/s]\u001b[A\n",
      "  1%|          | 121/14881 [00:00<00:37, 394.84it/s]\u001b[A\n",
      "  1%|          | 170/14881 [00:00<00:35, 418.15it/s]\u001b[A\n",
      "  1%|▏         | 208/14881 [00:00<00:36, 405.76it/s]\u001b[A\n",
      "  2%|▏         | 258/14881 [00:00<00:34, 429.27it/s]\u001b[A\n",
      "  2%|▏         | 308/14881 [00:00<00:32, 445.70it/s]\u001b[A\n",
      "  3%|▎         | 381/14881 [00:00<00:29, 495.79it/s]\u001b[A\n",
      "  3%|▎         | 431/14881 [00:00<00:34, 421.94it/s]\u001b[A\n",
      "  3%|▎         | 475/14881 [00:01<00:35, 402.08it/s]\u001b[A\n",
      "  3%|▎         | 517/14881 [00:01<00:35, 404.59it/s]\u001b[A\n",
      "  4%|▍         | 567/14881 [00:01<00:34, 420.92it/s]\u001b[A\n",
      "  4%|▍         | 619/14881 [00:01<00:31, 446.34it/s]\u001b[A\n",
      "  4%|▍         | 665/14881 [00:01<00:34, 412.33it/s]\u001b[A\n",
      "  5%|▍         | 708/14881 [00:01<00:39, 357.46it/s]\u001b[A\n",
      "  5%|▌         | 746/14881 [00:01<00:47, 300.29it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-015b9a82ebad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"posTag\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mnew_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f14ee19086fe>\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(word, postag, next_not)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpostag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Noun\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenti_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.n.0'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpostag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Verb\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# VERB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msenti_synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.v.0'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fatih/miniconda3/lib/python3.5/site-packages/nltk/corpus/reader/sentiwordnet.py\u001b[0m in \u001b[0;36msenti_synset\u001b[0;34m(self, *vals)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_db\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mSentiSynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' All words '''\n",
    "sentiments = []\n",
    "for idx, sentence in enumerate(tqdm.tqdm(jsonSentences)):\n",
    "    total = 0.0\n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        flag = 0\n",
    "        new_tag = \"\"\n",
    "        if (word[\"word\"] == \"unk\"):\n",
    "            continue\n",
    "        try:\n",
    "            if (i != (len(sentence) -1) and sentence[i+1][\"word\"] == \"not\"):\n",
    "                flag = 1\n",
    "            elif (i != 0 and sentence[i-1][\"word\"] == \"bad\"):\n",
    "                flag = 1\n",
    "            scores = get_score(word[\"word\"], word[\"posTag\"], flag)\n",
    "            if (not scores):\n",
    "                new_tag = eng_tag(word[\"word\"])\n",
    "                scores = get_score(word[\"word\"], new_tag, flag)\n",
    "            score = calculate_one_score(scores[:3])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(idx)\n",
    "            continue\n",
    "        total += score\n",
    "    sentiments.append(total)\n",
    "# for i in range(len(sentiments)):\n",
    "#     print(\"{0}. Sentence: {1:.3f}\".format(i+1, sentiments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14881/14881 [00:27<00:00, 540.72it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Only adjectives and noun '''\n",
    "sentiments = []\n",
    "l = len(jsonSentences)\n",
    "for idx, sentence in enumerate(tqdm.tqdm(jsonSentences)):\n",
    "    total = 0.0\n",
    "    n_sent = \"\"\n",
    "    for i in range(len(sentence)):\n",
    "        word = sentence[i]\n",
    "        flag = 0\n",
    "        new_tag = \"\"\n",
    "        if (word[\"posTag\"] == \"Adjective\"):\n",
    "            try:\n",
    "                if (i != (len(sentence) -1) and sentence[i+1][\"word\"] == \"not\"):\n",
    "                    flag = 1\n",
    "                elif (i != 0 and sentence[i-1][\"word\"] == \"bad\"):\n",
    "                    flag = 1\n",
    "                scores = get_score(word[\"word\"], word[\"posTag\"], flag)\n",
    "                if (not scores):\n",
    "                    new_tag = eng_tag(word[\"word\"])\n",
    "                    scores = get_score(word[\"word\"], new_tag, flag)\n",
    "                score = calculate_one_score(scores[:3])\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        elif (i != 0 and word[\"posTag\"] == \"Noun\" and sentence[i-1][\"posTag\"] == \"Adjective\"):\n",
    "            try:\n",
    "                if (i != (len(sentence) -1) and sentence[i+1][\"word\"] == \"not\"):\n",
    "                    flag = 1\n",
    "                elif (i != 0 and sentence[i-1][\"word\"] == \"bad\"):\n",
    "                    flag = 1\n",
    "                scores = get_score(word[\"word\"], word[\"posTag\"], flag)\n",
    "                if (not scores):\n",
    "                    new_tag = eng_tag(word[\"word\"])\n",
    "                    scores = get_score(word[\"word\"], new_tag, flag)\n",
    "                score = calculate_one_score(scores[:3])\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        n_sent += str(word[\"word\"] + \" \").lower()\n",
    "        total += score\n",
    "    sentiments.append(total)\n",
    "# for i in range(len(sentiments)):\n",
    "#     print(\"{0}. Sentence: {1:.3f}\".format(i+1, sentiments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7538/14881\n"
     ]
    }
   ],
   "source": [
    "true_preds = sum(1 for x in sentiments if x < 0)\n",
    "total = len(sentiments)\n",
    "print(str(true_preds)+\"/\"+str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "false_positive = {}\n",
    "for i in range(len(sentiments)):\n",
    "    if sentiments[i] > 0:\n",
    "        false_positive = {i, sentiments[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 16, 19, 20, 21, 24, 27, 28, 30, 31, 32, 33, 34, 36, 37, 40, 42, 44, 46]\n"
     ]
    }
   ],
   "source": [
    "print(false_positive[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"false_pos.txt\", 'w') as falses:\n",
    "    falses.writelines(str(false_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9955808080808082, 14877}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_score(word, postag, next_not):\n",
    "    scores = []\n",
    "    counter = 1\n",
    "    true_score = 0\n",
    "    while True:\n",
    "        try:\n",
    "            if postag == \"Noun\":  # NOUN\n",
    "                score = swn.senti_synset(word + '.n.0' + str(counter))\n",
    "            elif postag == \"Verb\":  # VERB\n",
    "                score = swn.senti_synset(word + '.v.0' + str(counter))\n",
    "            elif postag == \"Adjective\":  # ADJECTIVE\n",
    "                score = swn.senti_synset(word + '.a.0' + str(counter))\n",
    "            elif postag == \"Adverb\":  # ADVERB\n",
    "                score = swn.senti_synset(word + '.r.0' + str(counter))\n",
    "\n",
    "            true_score = score.pos_score() - score.neg_score()\n",
    "            if (next_not == 1 and true_score > 0):\n",
    "                true_score = true_score * (-1)\n",
    "            scores.append(true_score)\n",
    "            counter += 1\n",
    "        except Exception as e:\n",
    "#                 print(e)\n",
    "                break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_one_score(scores):\n",
    "    if len(scores) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "    for i in range(len(scores)):\n",
    "        numerator += scores[i] * (1 / (i+2))\n",
    "        denominator += 1 / (i+1)\n",
    "    return numerator / denominator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def eng_tag(word):\n",
    "    lst = [word]\n",
    "    raw = pos_tag(lst)\n",
    "    eng_pos = raw[0][1]\n",
    "    if eng_pos == \"NN\":\n",
    "        return \"Noun\"\n",
    "    elif eng_pos == \"VB\":\n",
    "        return \"Verb\"\n",
    "    elif eng_pos == \"RB\":\n",
    "        return \"Adverb\"\n",
    "    elif eng_pos == \"JJ\":\n",
    "        return \"Adjective\"\n",
    "    else:\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
